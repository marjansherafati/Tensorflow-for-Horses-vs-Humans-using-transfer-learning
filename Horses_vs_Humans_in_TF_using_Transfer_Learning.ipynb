{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Horses vs Humans in TF using Transfer Learning",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marjansherafati/Tensorflow-for-Horses-vs-Humans-using-transfer-learning/blob/master/Horses_vs_Humans_in_TF_using_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWUVe3DajrUI",
        "colab_type": "text"
      },
      "source": [
        "# Horses vs Humans classification in Tensorflow using Transfer Learning\n",
        "\n",
        "The goal in this notebook is to use a pre-trained model from Inception V3 and use it to train a horses vs humans classifier with a 99.9% accuracy.\n",
        "\n",
        "The beauty of transfer learning is that we can use models that were developed by other researchers, possibly using larger datasets and better machines, and we can build our model on top of that.\n",
        "\n",
        "For more information about the inception V3 model, please visit https://cloud.google.com/tpu/docs/inception-v3-advanced\n",
        "\n",
        "We start by importing all the necessary files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDpaAwTVkHhq",
        "colab_type": "text"
      },
      "source": [
        "Next we download the pre-trained model, and the weights for it.\n",
        "\n",
        "we then specify that we want the model to take the local weights that we separately downloaded\n",
        "\n",
        "We also set all layers in the pre_trained model to be non-trainable. This way, our neural network will not attempt to learn the weights that we already have, and will focus on training the lower dense layers of the neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "outputId": "47a5e5c9-4f3c-48ae-c8ad-0544e8332fee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape= (150, 150, 3),\n",
        "                                include_top = False,\n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  \n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-14 17:37:29--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 209.85.147.128, 2607:f8b0:4001:c08::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|209.85.147.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   181MB/s    in 0.5s    \n",
            "\n",
            "2019-10-14 17:37:30 (181 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 74, 74, 32)   96          conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 74, 74, 32)   0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 72, 72, 32)   9216        activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 72, 72, 32)   96          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 72, 72, 32)   0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 72, 72, 64)   18432       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 72, 72, 64)   192         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 72, 72, 64)   0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 35, 35, 80)   240         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 35, 35, 80)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 33, 33, 192)  138240      activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 33, 33, 192)  576         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 33, 33, 192)  0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 16, 16, 64)   192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 16, 16, 64)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 16, 16, 96)   55296       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 16, 16, 48)   144         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 16, 16, 96)   288         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 16, 16, 48)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 16, 16, 96)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 16, 16, 192)  0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 16, 16, 64)   76800       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 16, 16, 96)   82944       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 16, 16, 64)   192         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 16, 16, 64)   192         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 16, 16, 96)   288         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 16, 16, 32)   96          conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 16, 16, 64)   0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 16, 16, 64)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 16, 16, 96)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 16, 16, 32)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_99[0][0]              \n",
            "                                                                 activation_101[0][0]             \n",
            "                                                                 activation_104[0][0]             \n",
            "                                                                 activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 16, 16, 64)   192         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 16, 16, 64)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 16, 16, 96)   55296       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 16, 16, 48)   144         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 16, 16, 96)   288         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 16, 16, 48)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 16, 16, 96)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 16, 16, 64)   76800       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 16, 16, 96)   82944       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 16, 16, 64)   192         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 16, 16, 64)   192         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 16, 16, 96)   288         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 16, 16, 64)   192         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 16, 16, 64)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 16, 16, 64)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 16, 16, 96)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 16, 16, 64)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_106[0][0]             \n",
            "                                                                 activation_108[0][0]             \n",
            "                                                                 activation_111[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 16, 16, 64)   192         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 16, 16, 64)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 16, 16, 96)   55296       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 16, 16, 48)   144         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 16, 16, 96)   288         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 16, 16, 48)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 16, 16, 96)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 16, 16, 64)   76800       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 16, 16, 96)   82944       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 16, 16, 64)   192         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 16, 16, 64)   192         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 16, 16, 96)   288         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 16, 16, 64)   192         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 16, 16, 64)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 16, 16, 96)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 16, 16, 64)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_113[0][0]             \n",
            "                                                                 activation_115[0][0]             \n",
            "                                                                 activation_118[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 16, 16, 64)   192         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 16, 16, 64)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 16, 16, 96)   55296       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 16, 16, 96)   288         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 16, 16, 96)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 7, 7, 96)     82944       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 7, 7, 384)    1152        conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 7, 7, 96)     288         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 7, 7, 384)    0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 7, 7, 96)     0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_120[0][0]             \n",
            "                                                                 activation_123[0][0]             \n",
            "                                                                 max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 7, 7, 128)    384         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 7, 7, 128)    0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 7, 7, 128)    114688      activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 7, 7, 128)    384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 7, 7, 128)    0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 7, 7, 128)    114688      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 7, 7, 128)    384         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 7, 7, 128)    0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 7, 7, 128)    0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 7, 7, 128)    114688      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 7, 7, 128)    114688      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 7, 7, 128)    384         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 7, 7, 128)    0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 7, 7, 128)    0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 7, 7, 192)    172032      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 7, 7, 192)    172032      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 7, 7, 192)    576         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 7, 7, 192)    576         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 7, 7, 192)    576         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 7, 7, 192)    0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 7, 7, 192)    0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 7, 7, 192)    0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 7, 7, 192)    0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_124[0][0]             \n",
            "                                                                 activation_127[0][0]             \n",
            "                                                                 activation_132[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 7, 7, 160)    480         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 7, 7, 160)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 7, 7, 160)    179200      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 7, 7, 160)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 7, 7, 160)    179200      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 7, 7, 160)    480         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 7, 7, 160)    480         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 7, 7, 160)    0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 7, 7, 160)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 7, 7, 160)    179200      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 7, 7, 160)    179200      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 7, 7, 160)    480         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 7, 7, 160)    480         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 7, 7, 160)    0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 7, 7, 160)    0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 7, 7, 192)    215040      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 7, 7, 192)    215040      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 7, 7, 192)    576         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 7, 7, 192)    576         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 7, 7, 192)    576         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 7, 7, 192)    576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 7, 7, 192)    0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 7, 7, 192)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 7, 7, 192)    0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 7, 7, 192)    0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_134[0][0]             \n",
            "                                                                 activation_137[0][0]             \n",
            "                                                                 activation_142[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 7, 7, 160)    480         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 7, 7, 160)    0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 7, 7, 160)    179200      activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 7, 7, 160)    480         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 7, 7, 160)    0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 7, 7, 160)    179200      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 7, 7, 160)    480         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 7, 7, 160)    480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 7, 7, 160)    0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 7, 7, 160)    0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 7, 7, 160)    179200      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 7, 7, 160)    179200      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 7, 7, 160)    480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 7, 7, 160)    0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 7, 7, 160)    0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 7, 7, 192)    215040      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 7, 7, 192)    215040      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 7, 7, 192)    576         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 7, 7, 192)    576         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 7, 7, 192)    0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 7, 7, 192)    0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 7, 7, 192)    0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 7, 7, 192)    0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_144[0][0]             \n",
            "                                                                 activation_147[0][0]             \n",
            "                                                                 activation_152[0][0]             \n",
            "                                                                 activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 7, 7, 192)    576         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 7, 7, 192)    0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 7, 7, 192)    258048      activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 7, 7, 192)    576         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 7, 7, 192)    0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 7, 7, 192)    258048      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 7, 7, 192)    576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 7, 7, 192)    0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 7, 7, 192)    0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 7, 7, 192)    258048      activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 7, 7, 192)    258048      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 7, 7, 192)    0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 7, 7, 192)    0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 7, 7, 192)    258048      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 7, 7, 192)    258048      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 7, 7, 192)    576         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 7, 7, 192)    576         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 7, 7, 192)    576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 7, 7, 192)    0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 7, 7, 192)    0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 7, 7, 192)    0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 7, 7, 192)    0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_154[0][0]             \n",
            "                                                                 activation_157[0][0]             \n",
            "                                                                 activation_162[0][0]             \n",
            "                                                                 activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 7, 7, 192)    576         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 7, 7, 192)    0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 7, 7, 192)    258048      activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 7, 7, 192)    576         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 7, 7, 192)    0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 7, 7, 192)    258048      activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 7, 7, 192)    576         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 7, 7, 192)    576         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 7, 7, 192)    0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 7, 7, 192)    0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 3, 3, 320)    552960      activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 3, 3, 192)    331776      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 3, 3, 320)    960         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 3, 3, 192)    576         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 3, 3, 320)    0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 3, 3, 192)    0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_165[0][0]             \n",
            "                                                                 activation_169[0][0]             \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 3, 3, 448)    1344        conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 3, 3, 448)    0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 3, 3, 384)    1548288     activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 3, 3, 384)    1152        conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 3, 3, 384)    1152        conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 3, 3, 384)    0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 3, 3, 384)    0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 3, 3, 384)    442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 3, 3, 384)    442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 3, 3, 384)    442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 3, 3, 384)    442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_16 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 3, 3, 384)    1152        conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 3, 3, 384)    1152        conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 3, 3, 384)    1152        conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 3, 3, 384)    1152        conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 3, 3, 320)    960         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 3, 3, 384)    0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 3, 3, 384)    0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 3, 3, 384)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 3, 3, 384)    0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 3, 3, 192)    576         conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 3, 3, 320)    0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_172[0][0]             \n",
            "                                                                 activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 3, 3, 768)    0           activation_176[0][0]             \n",
            "                                                                 activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 3, 3, 192)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_170[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 3, 3, 448)    1344        conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 3, 3, 448)    0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 3, 3, 384)    1548288     activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 3, 3, 384)    1152        conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 3, 3, 384)    1152        conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 3, 3, 384)    0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 3, 3, 384)    0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 3, 3, 384)    442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 3, 3, 384)    442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 3, 3, 384)    442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 3, 3, 384)    442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_17 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 3, 3, 384)    1152        conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 3, 3, 384)    1152        conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 3, 3, 384)    1152        conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 3, 3, 384)    1152        conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 3, 3, 320)    960         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 3, 3, 384)    0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 3, 3, 384)    0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 3, 3, 384)    0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 3, 3, 384)    0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 3, 3, 192)    576         conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 3, 3, 320)    0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_181[0][0]             \n",
            "                                                                 activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 3, 3, 768)    0           activation_185[0][0]             \n",
            "                                                                 activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 3, 3, 192)    0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_179[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_3[0][0]              \n",
            "                                                                 activation_187[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "outputId": "fd7185ff-9f3d-4a4a-c9bb-036204710381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JtjzgMlkq4U",
        "colab_type": "text"
      },
      "source": [
        "We also want to have a callback function, so that we can stop training once we reached the desired accuracy (99.9%)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hafbyzEkyim",
        "colab_type": "text"
      },
      "source": [
        "Next I will define the dense layers that I want to put on top of the pre-trained model, to train for the task in hand.\n",
        "\n",
        "I first flatten the output from the last pre-trained layer, add two dense layers (one fully connected layer with 1024 units and one output layer with one sigmoid unit) and compile the model.\n",
        "\n",
        "As in previous notebooks, I am using RMSprop as my optimizer (more info at https://towardsdatascience.com/understanding-rmsprop-faster-neural-network-learning-62e116fcf29a), and binary cross-entropy as my loss function\n",
        "\n",
        "I'm also using a dropout rate of 0.2 to avoid overfitting in my training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "outputId": "fb41cb4c-f991-44fb-f59e-41f6870a7184",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model(pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 74, 74, 32)   96          conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 74, 74, 32)   0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 72, 72, 32)   9216        activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 72, 72, 32)   96          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 72, 72, 32)   0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 72, 72, 64)   18432       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 72, 72, 64)   192         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 72, 72, 64)   0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 35, 35, 80)   240         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 35, 35, 80)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 33, 33, 192)  138240      activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 33, 33, 192)  576         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 33, 33, 192)  0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 16, 16, 64)   192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 16, 16, 64)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 16, 16, 96)   55296       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 16, 16, 48)   144         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 16, 16, 96)   288         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 16, 16, 48)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 16, 16, 96)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 16, 16, 192)  0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 16, 16, 64)   76800       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 16, 16, 96)   82944       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 16, 16, 64)   192         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 16, 16, 64)   192         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 16, 16, 96)   288         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 16, 16, 32)   96          conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 16, 16, 64)   0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 16, 16, 64)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 16, 16, 96)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 16, 16, 32)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_99[0][0]              \n",
            "                                                                 activation_101[0][0]             \n",
            "                                                                 activation_104[0][0]             \n",
            "                                                                 activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 16, 16, 64)   192         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 16, 16, 64)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 16, 16, 96)   55296       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 16, 16, 48)   144         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 16, 16, 96)   288         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 16, 16, 48)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 16, 16, 96)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 16, 16, 64)   76800       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 16, 16, 96)   82944       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 16, 16, 64)   192         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 16, 16, 64)   192         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 16, 16, 96)   288         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 16, 16, 64)   192         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 16, 16, 64)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 16, 16, 64)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 16, 16, 96)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 16, 16, 64)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_106[0][0]             \n",
            "                                                                 activation_108[0][0]             \n",
            "                                                                 activation_111[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 16, 16, 64)   192         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 16, 16, 64)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 16, 16, 96)   55296       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 16, 16, 48)   144         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 16, 16, 96)   288         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 16, 16, 48)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 16, 16, 96)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 16, 16, 64)   76800       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 16, 16, 96)   82944       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 16, 16, 64)   192         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 16, 16, 64)   192         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 16, 16, 96)   288         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 16, 16, 64)   192         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 16, 16, 64)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 16, 16, 96)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 16, 16, 64)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_113[0][0]             \n",
            "                                                                 activation_115[0][0]             \n",
            "                                                                 activation_118[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 16, 16, 64)   192         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 16, 16, 64)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 16, 16, 96)   55296       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 16, 16, 96)   288         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 16, 16, 96)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 7, 7, 96)     82944       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 7, 7, 384)    1152        conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 7, 7, 96)     288         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 7, 7, 384)    0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 7, 7, 96)     0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_120[0][0]             \n",
            "                                                                 activation_123[0][0]             \n",
            "                                                                 max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 7, 7, 128)    384         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 7, 7, 128)    0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 7, 7, 128)    114688      activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 7, 7, 128)    384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 7, 7, 128)    0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 7, 7, 128)    114688      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 7, 7, 128)    384         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 7, 7, 128)    0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 7, 7, 128)    0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 7, 7, 128)    114688      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 7, 7, 128)    114688      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 7, 7, 128)    384         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 7, 7, 128)    0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 7, 7, 128)    0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 7, 7, 192)    172032      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 7, 7, 192)    172032      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 7, 7, 192)    576         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 7, 7, 192)    576         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 7, 7, 192)    576         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 7, 7, 192)    0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 7, 7, 192)    0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 7, 7, 192)    0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 7, 7, 192)    0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_124[0][0]             \n",
            "                                                                 activation_127[0][0]             \n",
            "                                                                 activation_132[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 7, 7, 160)    480         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 7, 7, 160)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 7, 7, 160)    179200      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 7, 7, 160)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 7, 7, 160)    179200      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 7, 7, 160)    480         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 7, 7, 160)    480         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 7, 7, 160)    0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 7, 7, 160)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 7, 7, 160)    179200      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 7, 7, 160)    179200      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 7, 7, 160)    480         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 7, 7, 160)    480         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 7, 7, 160)    0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 7, 7, 160)    0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 7, 7, 192)    215040      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 7, 7, 192)    215040      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 7, 7, 192)    576         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 7, 7, 192)    576         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 7, 7, 192)    576         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 7, 7, 192)    576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 7, 7, 192)    0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 7, 7, 192)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 7, 7, 192)    0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 7, 7, 192)    0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_134[0][0]             \n",
            "                                                                 activation_137[0][0]             \n",
            "                                                                 activation_142[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 7, 7, 160)    480         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 7, 7, 160)    0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 7, 7, 160)    179200      activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 7, 7, 160)    480         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 7, 7, 160)    0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 7, 7, 160)    179200      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 7, 7, 160)    480         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 7, 7, 160)    480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 7, 7, 160)    0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 7, 7, 160)    0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 7, 7, 160)    179200      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 7, 7, 160)    179200      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 7, 7, 160)    480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 7, 7, 160)    0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 7, 7, 160)    0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 7, 7, 192)    215040      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 7, 7, 192)    215040      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 7, 7, 192)    576         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 7, 7, 192)    576         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 7, 7, 192)    0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 7, 7, 192)    0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 7, 7, 192)    0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 7, 7, 192)    0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_144[0][0]             \n",
            "                                                                 activation_147[0][0]             \n",
            "                                                                 activation_152[0][0]             \n",
            "                                                                 activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 7, 7, 192)    576         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 7, 7, 192)    0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 7, 7, 192)    258048      activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 7, 7, 192)    576         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 7, 7, 192)    0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 7, 7, 192)    258048      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 7, 7, 192)    576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 7, 7, 192)    0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 7, 7, 192)    0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 7, 7, 192)    258048      activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 7, 7, 192)    258048      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 7, 7, 192)    0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 7, 7, 192)    0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 7, 7, 192)    258048      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 7, 7, 192)    258048      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 7, 7, 192)    576         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 7, 7, 192)    576         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 7, 7, 192)    576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 7, 7, 192)    0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 7, 7, 192)    0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 7, 7, 192)    0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 7, 7, 192)    0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_154[0][0]             \n",
            "                                                                 activation_157[0][0]             \n",
            "                                                                 activation_162[0][0]             \n",
            "                                                                 activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zF3PImQmHGf",
        "colab_type": "text"
      },
      "source": [
        "# Data Pre-processing\n",
        "\n",
        "In this section, I download the horse vs human dataset. More info about this dataset can be found at http://www.laurencemoroney.com/horses-or-humans-dataset/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "outputId": "3e1b6c1e-5ea1-48be-fc9f-bf8355a3d691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-14 17:40:00--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.212.128, 2607:f8b0:4001:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.212.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M   157MB/s    in 0.9s    \n",
            "\n",
            "2019-10-14 17:40:01 (157 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-10-14 17:40:01--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.111.128, 2607:f8b0:4001:c05::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.111.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-10-14 17:40:01 (108 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "outputId": "7312ca97-dd33-4d15-baf8-c03c0a49a021",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "train_horses_dir = \"/tmp/training/horses/\"\n",
        "train_humans_dir = \"/tmp/training/humans/\"\n",
        "validation_horses_dir = \"/tmp/validation/horses/\"\n",
        "validation_humans_dir = \"/tmp/validation/humans/\"\n",
        "\n",
        "\n",
        "print(len(os.listdir(\"/tmp/training/horses/\")))\n",
        "print(len(os.listdir(\"/tmp/training/humans/\")))\n",
        "print(len(os.listdir(\"/tmp/validation/horses/\")))\n",
        "print(len(os.listdir(\"/tmp/validation/humans/\")))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLH--4iTmneM",
        "colab_type": "text"
      },
      "source": [
        "Next, I use ImageDataGenerator to create the input data, and perform data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "973769d2-ffda-41a4-bdce-b9c78d73dc48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(      \n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode ='binary',\n",
        "                                                    target_size=(150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode ='binary',\n",
        "                                                    target_size=(150, 150))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgloEqMSm2W3",
        "colab_type": "text"
      },
      "source": [
        "In the code block below, I fit the model to the data. I have allowed the model to continue for 100 epochs, but we will stop the training once the training set accuracy has reached 99.9%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "0956da3b-ed84-4ea0-9c64-1517b8d5defe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(train_generator,\n",
        "                              epochs=100,\n",
        "                              verbose = 1,\n",
        "                              validation_data = validation_generator,\n",
        "                              callbacks = [callbacks])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.2924 - acc: 0.8699Epoch 1/100\n",
            "52/52 [==============================] - 23s 449ms/step - loss: 0.2878 - acc: 0.8724 - val_loss: 0.0032 - val_acc: 1.0000\n",
            "Epoch 2/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0975 - acc: 0.9603Epoch 1/100\n",
            "52/52 [==============================] - 13s 241ms/step - loss: 0.0972 - acc: 0.9601 - val_loss: 5.4832e-04 - val_acc: 1.0000\n",
            "Epoch 3/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9732Epoch 1/100\n",
            "52/52 [==============================] - 14s 268ms/step - loss: 0.0683 - acc: 0.9737 - val_loss: 0.0032 - val_acc: 1.0000\n",
            "Epoch 4/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9782Epoch 1/100\n",
            "52/52 [==============================] - 14s 269ms/step - loss: 0.0644 - acc: 0.9786 - val_loss: 0.0014 - val_acc: 1.0000\n",
            "Epoch 5/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0728 - acc: 0.9742Epoch 1/100\n",
            "52/52 [==============================] - 14s 269ms/step - loss: 0.0716 - acc: 0.9747 - val_loss: 0.0033 - val_acc: 0.9961\n",
            "Epoch 6/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9891Epoch 1/100\n",
            "52/52 [==============================] - 14s 271ms/step - loss: 0.0311 - acc: 0.9883 - val_loss: 0.0863 - val_acc: 0.9766\n",
            "Epoch 7/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9881Epoch 1/100\n",
            "52/52 [==============================] - 14s 270ms/step - loss: 0.0407 - acc: 0.9883 - val_loss: 7.2891e-05 - val_acc: 1.0000\n",
            "Epoch 8/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9851Epoch 1/100\n",
            "52/52 [==============================] - 14s 271ms/step - loss: 0.0419 - acc: 0.9854 - val_loss: 0.0115 - val_acc: 0.9961\n",
            "Epoch 9/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9911Epoch 1/100\n",
            "52/52 [==============================] - 14s 270ms/step - loss: 0.0253 - acc: 0.9912 - val_loss: 0.0098 - val_acc: 0.9961\n",
            "Epoch 10/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9911Epoch 1/100\n",
            "52/52 [==============================] - 14s 267ms/step - loss: 0.0277 - acc: 0.9912 - val_loss: 0.0570 - val_acc: 0.9844\n",
            "Epoch 11/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9881Epoch 1/100\n",
            "52/52 [==============================] - 14s 271ms/step - loss: 0.0305 - acc: 0.9883 - val_loss: 0.0636 - val_acc: 0.9883\n",
            "Epoch 12/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9911Epoch 1/100\n",
            "52/52 [==============================] - 14s 268ms/step - loss: 0.0234 - acc: 0.9912 - val_loss: 0.1196 - val_acc: 0.9766\n",
            "Epoch 13/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9921Epoch 1/100\n",
            "52/52 [==============================] - 14s 268ms/step - loss: 0.0169 - acc: 0.9922 - val_loss: 0.4249 - val_acc: 0.9570\n",
            "Epoch 14/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9881Epoch 1/100\n",
            "52/52 [==============================] - 14s 271ms/step - loss: 0.0364 - acc: 0.9883 - val_loss: 0.1559 - val_acc: 0.9805\n",
            "Epoch 15/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9791Epoch 1/100\n",
            "52/52 [==============================] - 14s 271ms/step - loss: 0.0606 - acc: 0.9796 - val_loss: 0.2739 - val_acc: 0.9570\n",
            "Epoch 16/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9891Epoch 1/100\n",
            "52/52 [==============================] - 14s 268ms/step - loss: 0.0313 - acc: 0.9893 - val_loss: 0.0791 - val_acc: 0.9922\n",
            "Epoch 17/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9881Epoch 1/100\n",
            "52/52 [==============================] - 14s 268ms/step - loss: 0.0289 - acc: 0.9883 - val_loss: 0.3864 - val_acc: 0.9570\n",
            "Epoch 18/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9881Epoch 1/100\n",
            "52/52 [==============================] - 14s 274ms/step - loss: 0.0536 - acc: 0.9873 - val_loss: 0.1821 - val_acc: 0.9648\n",
            "Epoch 19/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9921Epoch 1/100\n",
            "52/52 [==============================] - 14s 268ms/step - loss: 0.0214 - acc: 0.9922 - val_loss: 0.2061 - val_acc: 0.9648\n",
            "Epoch 20/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9921Epoch 1/100\n",
            "52/52 [==============================] - 14s 270ms/step - loss: 0.0240 - acc: 0.9922 - val_loss: 0.2588 - val_acc: 0.9688\n",
            "Epoch 21/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9940Epoch 1/100\n",
            "52/52 [==============================] - 14s 274ms/step - loss: 0.0191 - acc: 0.9942 - val_loss: 0.2770 - val_acc: 0.9688\n",
            "Epoch 22/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9921Epoch 1/100\n",
            "52/52 [==============================] - 14s 269ms/step - loss: 0.0174 - acc: 0.9922 - val_loss: 0.1851 - val_acc: 0.9844\n",
            "Epoch 23/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9950Epoch 1/100\n",
            "52/52 [==============================] - 14s 268ms/step - loss: 0.0257 - acc: 0.9951 - val_loss: 0.1000 - val_acc: 0.9922\n",
            "Epoch 24/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9950Epoch 1/100\n",
            "52/52 [==============================] - 14s 268ms/step - loss: 0.0145 - acc: 0.9951 - val_loss: 0.1479 - val_acc: 0.9844\n",
            "Epoch 25/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9960Epoch 1/100\n",
            "52/52 [==============================] - 14s 265ms/step - loss: 0.0188 - acc: 0.9961 - val_loss: 0.1454 - val_acc: 0.9766\n",
            "Epoch 26/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9930Epoch 1/100\n",
            "52/52 [==============================] - 14s 268ms/step - loss: 0.0304 - acc: 0.9932 - val_loss: 0.1995 - val_acc: 0.9727\n",
            "Epoch 27/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9980Epoch 1/100\n",
            "52/52 [==============================] - 14s 268ms/step - loss: 0.0209 - acc: 0.9981 - val_loss: 0.0895 - val_acc: 0.9922\n",
            "Epoch 28/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9970Epoch 1/100\n",
            "52/52 [==============================] - 14s 272ms/step - loss: 0.0099 - acc: 0.9971 - val_loss: 0.2180 - val_acc: 0.9688\n",
            "Epoch 29/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9940Epoch 1/100\n",
            "52/52 [==============================] - 14s 270ms/step - loss: 0.0185 - acc: 0.9942 - val_loss: 0.2157 - val_acc: 0.9766\n",
            "Epoch 30/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9970Epoch 1/100\n",
            "52/52 [==============================] - 14s 267ms/step - loss: 0.0142 - acc: 0.9971 - val_loss: 0.1611 - val_acc: 0.9766\n",
            "Epoch 31/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9940Epoch 1/100\n",
            "52/52 [==============================] - 14s 270ms/step - loss: 0.0185 - acc: 0.9942 - val_loss: 0.1253 - val_acc: 0.9844\n",
            "Epoch 32/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9980Epoch 1/100\n",
            "52/52 [==============================] - 14s 269ms/step - loss: 0.0060 - acc: 0.9981 - val_loss: 0.2633 - val_acc: 0.9727\n",
            "Epoch 33/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9911Epoch 1/100\n",
            "52/52 [==============================] - 14s 270ms/step - loss: 0.0487 - acc: 0.9912 - val_loss: 0.1061 - val_acc: 0.9844\n",
            "Epoch 34/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9881Epoch 1/100\n",
            "52/52 [==============================] - 14s 268ms/step - loss: 0.0342 - acc: 0.9883 - val_loss: 0.4656 - val_acc: 0.9609\n",
            "Epoch 35/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9950Epoch 1/100\n",
            "52/52 [==============================] - 14s 273ms/step - loss: 0.0253 - acc: 0.9942 - val_loss: 0.5146 - val_acc: 0.9531\n",
            "Epoch 36/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9950Epoch 1/100\n",
            "52/52 [==============================] - 14s 267ms/step - loss: 0.0182 - acc: 0.9951 - val_loss: 0.2728 - val_acc: 0.9727\n",
            "Epoch 37/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9921Epoch 1/100\n",
            "52/52 [==============================] - 14s 266ms/step - loss: 0.0276 - acc: 0.9922 - val_loss: 0.1430 - val_acc: 0.9844\n",
            "Epoch 38/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9921Epoch 1/100\n",
            "52/52 [==============================] - 14s 269ms/step - loss: 0.0222 - acc: 0.9922 - val_loss: 0.2381 - val_acc: 0.9727\n",
            "Epoch 39/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9960Epoch 1/100\n",
            "52/52 [==============================] - 14s 268ms/step - loss: 0.0140 - acc: 0.9961 - val_loss: 0.6228 - val_acc: 0.9531\n",
            "Epoch 40/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9921Epoch 1/100\n",
            "52/52 [==============================] - 14s 265ms/step - loss: 0.0228 - acc: 0.9922 - val_loss: 0.0717 - val_acc: 0.9922\n",
            "Epoch 41/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9940Epoch 1/100\n",
            "52/52 [==============================] - 14s 271ms/step - loss: 0.0195 - acc: 0.9942 - val_loss: 0.2224 - val_acc: 0.9766\n",
            "Epoch 42/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9950Epoch 1/100\n",
            "52/52 [==============================] - 14s 267ms/step - loss: 0.0194 - acc: 0.9951 - val_loss: 0.3272 - val_acc: 0.9648\n",
            "Epoch 43/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9980Epoch 1/100\n",
            "52/52 [==============================] - 14s 266ms/step - loss: 0.0062 - acc: 0.9981 - val_loss: 0.3768 - val_acc: 0.9648\n",
            "Epoch 44/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9970Epoch 1/100\n",
            "52/52 [==============================] - 14s 269ms/step - loss: 0.0073 - acc: 0.9971 - val_loss: 0.3027 - val_acc: 0.9648\n",
            "Epoch 45/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9930Epoch 1/100\n",
            "52/52 [==============================] - 14s 274ms/step - loss: 0.0268 - acc: 0.9932 - val_loss: 0.2163 - val_acc: 0.9805\n",
            "Epoch 46/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9970Epoch 1/100\n",
            "52/52 [==============================] - 14s 269ms/step - loss: 0.0068 - acc: 0.9971 - val_loss: 0.2264 - val_acc: 0.9766\n",
            "Epoch 47/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9960Epoch 1/100\n",
            "52/52 [==============================] - 14s 266ms/step - loss: 0.0127 - acc: 0.9961 - val_loss: 0.6945 - val_acc: 0.9531\n",
            "Epoch 48/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9950Epoch 1/100\n",
            "52/52 [==============================] - 14s 269ms/step - loss: 0.0376 - acc: 0.9942 - val_loss: 0.1312 - val_acc: 0.9883\n",
            "Epoch 49/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9960Epoch 1/100\n",
            "52/52 [==============================] - 14s 267ms/step - loss: 0.0100 - acc: 0.9961 - val_loss: 0.3747 - val_acc: 0.9609\n",
            "Epoch 50/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9960Epoch 1/100\n",
            "52/52 [==============================] - 14s 272ms/step - loss: 0.0226 - acc: 0.9961 - val_loss: 0.4485 - val_acc: 0.9648\n",
            "Epoch 51/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9950Epoch 1/100\n",
            "52/52 [==============================] - 14s 268ms/step - loss: 0.0204 - acc: 0.9951 - val_loss: 0.4465 - val_acc: 0.9648\n",
            "Epoch 52/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9970Epoch 1/100\n",
            "52/52 [==============================] - 14s 272ms/step - loss: 0.0132 - acc: 0.9971 - val_loss: 0.3064 - val_acc: 0.9688\n",
            "Epoch 53/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9960Epoch 1/100\n",
            "52/52 [==============================] - 14s 268ms/step - loss: 0.0141 - acc: 0.9961 - val_loss: 0.3065 - val_acc: 0.9766\n",
            "Epoch 54/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9921Epoch 1/100\n",
            "52/52 [==============================] - 14s 266ms/step - loss: 0.0182 - acc: 0.9922 - val_loss: 0.3857 - val_acc: 0.9648\n",
            "Epoch 55/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9921Epoch 1/100\n",
            "52/52 [==============================] - 14s 267ms/step - loss: 0.0209 - acc: 0.9912 - val_loss: 0.3730 - val_acc: 0.9609\n",
            "Epoch 56/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9960Epoch 1/100\n",
            "52/52 [==============================] - 14s 266ms/step - loss: 0.0140 - acc: 0.9961 - val_loss: 0.7816 - val_acc: 0.9531\n",
            "Epoch 57/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9970Epoch 1/100\n",
            "52/52 [==============================] - 14s 266ms/step - loss: 0.0054 - acc: 0.9971 - val_loss: 0.7580 - val_acc: 0.9531\n",
            "Epoch 58/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9960Epoch 1/100\n",
            "52/52 [==============================] - 14s 273ms/step - loss: 0.0103 - acc: 0.9951 - val_loss: 0.5695 - val_acc: 0.9570\n",
            "Epoch 59/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9950Epoch 1/100\n",
            "52/52 [==============================] - 14s 272ms/step - loss: 0.0134 - acc: 0.9951 - val_loss: 0.5362 - val_acc: 0.9570\n",
            "Epoch 60/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9930Epoch 1/100\n",
            "52/52 [==============================] - 14s 272ms/step - loss: 0.0290 - acc: 0.9922 - val_loss: 0.3672 - val_acc: 0.9688\n",
            "Epoch 61/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9911Epoch 1/100\n",
            "52/52 [==============================] - 14s 268ms/step - loss: 0.0208 - acc: 0.9912 - val_loss: 0.3177 - val_acc: 0.9766\n",
            "Epoch 62/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9911Epoch 1/100\n",
            "52/52 [==============================] - 14s 272ms/step - loss: 0.0317 - acc: 0.9903 - val_loss: 0.2343 - val_acc: 0.9805\n",
            "Epoch 63/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9941Epoch 1/100\n",
            "52/52 [==============================] - 14s 273ms/step - loss: 0.0323 - acc: 0.9942 - val_loss: 0.4309 - val_acc: 0.9688\n",
            "Epoch 64/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9940Epoch 1/100\n",
            "52/52 [==============================] - 14s 268ms/step - loss: 0.0322 - acc: 0.9932 - val_loss: 0.2863 - val_acc: 0.9688\n",
            "Epoch 65/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9950Epoch 1/100\n",
            "52/52 [==============================] - 14s 269ms/step - loss: 0.0093 - acc: 0.9951 - val_loss: 0.3941 - val_acc: 0.9688\n",
            "Epoch 66/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9960Epoch 1/100\n",
            "52/52 [==============================] - 14s 271ms/step - loss: 0.0158 - acc: 0.9961 - val_loss: 0.5766 - val_acc: 0.9609\n",
            "Epoch 67/100\n",
            "51/52 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 1.0000Epoch 1/100\n",
            "13/52 [======>.......................] - ETA: 4s - loss: 0.4376 - acc: 0.9688\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "52/52 [==============================] - 14s 270ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.4376 - val_acc: 0.9688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cB25j4anHW_",
        "colab_type": "text"
      },
      "source": [
        "we observe that after about 52 epochs, we reach the desired accuracy on the training set.\n",
        "\n",
        "Let's plot the training and validation accuracy vs epochs to see how accuracy is evolving with time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "outputId": "8262ffa4-0c06-46d3-c5e8-42c2e490946d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1v01nqznQdd",
        "colab_type": "text"
      },
      "source": [
        "As can be seen, the training set accuracy is increasing with each epoch, but the validation set accuracy is oscillating. This means that our methods of overffiting have still not done much to avoid overfitting on the training set"
      ]
    }
  ]
}